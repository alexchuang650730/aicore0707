# Stagewiseæµ‹è¯•æ¡†æ¶APIæ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹

## ğŸ“š **APIæ¦‚è§ˆ**

Stagewiseæµ‹è¯•æ¡†æ¶æä¾›äº†å®Œæ•´çš„æµ‹è¯•è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬å½•åˆ¶ã€ç”Ÿæˆã€éªŒè¯å’ŒæŠ¥å‘ŠåŠŸèƒ½ã€‚æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº†æ‰€æœ‰APIæ¥å£å’Œä½¿ç”¨æ–¹æ³•ã€‚

## ğŸš€ **å¿«é€Ÿå¼€å§‹**

### **å®‰è£…å’Œåˆå§‹åŒ–**
```python
from core.components.stagewise_mcp import (
    StagewiseService,
    EnhancedStagewiseTestingFramework,
    RecordAsTestOrchestrator,
    ActionRecognitionEngine,
    TestNodeGenerator,
    AGUIAutoGenerator,
    PlaybackVerificationEngine
)

# åˆå§‹åŒ–æ ¸å¿ƒæœåŠ¡
stagewise = StagewiseService()
framework = EnhancedStagewiseTestingFramework()
orchestrator = RecordAsTestOrchestrator()
```

### **åŸºæœ¬ä½¿ç”¨æµç¨‹**
```python
# 1. å¼€å§‹å½•åˆ¶ä¼šè¯
session_id = await orchestrator.start_record_as_test_session(
    name="ç™»å½•æµ‹è¯•",
    description="æµ‹è¯•ç”¨æˆ·ç™»å½•æµç¨‹"
)

# 2. ç”¨æˆ·è¿›è¡Œæ“ä½œ (ç³»ç»Ÿè‡ªåŠ¨å½•åˆ¶)
# ... ç”¨æˆ·åœ¨æµè§ˆå™¨ä¸­æ“ä½œ ...

# 3. å®Œæˆå½•åˆ¶å¹¶ç”Ÿæˆæµ‹è¯•
session = await orchestrator.execute_complete_workflow()

# 4. æŸ¥çœ‹ç”Ÿæˆçš„æ–‡ä»¶
print(f"ç”Ÿæˆçš„ç»„ä»¶: {session.component_files}")
print(f"æµ‹è¯•æ–‡ä»¶: {session.test_files}")
print(f"æŠ¥å‘Šæ–‡ä»¶: {session.report_files}")
```

## ğŸ”§ **æ ¸å¿ƒAPIæ¥å£**

### **1. StagewiseService API**

#### **åˆ›å»ºç¼–ç¨‹ä¼šè¯**
```python
async def create_session(
    user_id: str,
    project_id: str,
    browser_context: Dict[str, Any]
) -> StagewiseSession
```

**å‚æ•°:**
- `user_id`: ç”¨æˆ·ID
- `project_id`: é¡¹ç›®ID  
- `browser_context`: æµè§ˆå™¨ä¸Šä¸‹æ–‡ä¿¡æ¯

**è¿”å›:** StagewiseSessionå¯¹è±¡

**ç¤ºä¾‹:**
```python
session = await stagewise.create_session(
    user_id="user123",
    project_id="project456",
    browser_context={
        "url": "https://example.com",
        "viewport": {"width": 1920, "height": 1080},
        "user_agent": "Mozilla/5.0..."
    }
)
```

#### **é€‰æ‹©é¡µé¢å…ƒç´ **
```python
async def select_element(
    session_id: str,
    element_info: Dict[str, Any]
) -> ElementSelection
```

**å‚æ•°:**
- `session_id`: ä¼šè¯ID
- `element_info`: å…ƒç´ ä¿¡æ¯

**ç¤ºä¾‹:**
```python
element = await stagewise.select_element(
    session_id=session.session_id,
    element_info={
        "selector": "#login-button",
        "tag_name": "button",
        "text_content": "ç™»å½•",
        "position": {"x": 100, "y": 200}
    }
)
```

#### **ç”Ÿæˆä»£ç **
```python
async def generate_code(
    session_id: str,
    element_selection: ElementSelection,
    action_type: str
) -> GeneratedCode
```

**å‚æ•°:**
- `session_id`: ä¼šè¯ID
- `element_selection`: é€‰ä¸­çš„å…ƒç´ 
- `action_type`: åŠ¨ä½œç±»å‹ ("click", "input", "extract", "wait")

**ç¤ºä¾‹:**
```python
code = await stagewise.generate_code(
    session_id=session.session_id,
    element_selection=element,
    action_type="click"
)
print(code.generated_code)  # è¾“å‡ºç”Ÿæˆçš„Python/JavaScriptä»£ç 
```

### **2. TestRunner API**

#### **è¿è¡ŒP0æµ‹è¯•**
```python
async def run_p0_tests(config: Dict[str, Any] = None) -> TestSession
```

**ç¤ºä¾‹:**
```python
from core.components.stagewise_mcp.test_runner import StagewiseTestRunner

runner = StagewiseTestRunner()
session = await runner.run_p0_tests({
    "timeout": 60,
    "parallel": False,
    "output": "p0_test_report.json"
})

print(f"æµ‹è¯•ç»“æœ: {session.passed_tests}/{session.total_tests} é€šè¿‡")
```

#### **è¿è¡Œè‡ªå®šä¹‰æµ‹è¯•å¥—ä»¶**
```python
async def run_test_suite(suite_name: str) -> List[TestResult]
```

**ç¤ºä¾‹:**
```python
results = await framework.run_test_suite("ui_functionality_tests")
for result in results:
    print(f"{result.test_name}: {result.status}")
```

### **3. RecordAsTestOrchestrator API**

#### **é…ç½®å½•åˆ¶å³æµ‹è¯•**
```python
config = RecordAsTestConfig(
    # å½•åˆ¶é…ç½®
    auto_start_recording=True,
    recording_timeout=300.0,
    min_actions_required=3,
    
    # ç”Ÿæˆé…ç½®
    generate_react_components=True,
    generate_vue_components=False,
    generate_html_components=True,
    component_prefix="Test",
    
    # éªŒè¯é…ç½®
    auto_playback_verification=True,
    continue_on_verification_failure=True,
    verification_timeout=60.0,
    
    # è¾“å‡ºé…ç½®
    output_directory="my_test_output",
    export_components=True,
    export_test_suite=True,
    export_playback_report=True
)

orchestrator = RecordAsTestOrchestrator(config)
```

#### **å¼€å§‹å½•åˆ¶ä¼šè¯**
```python
async def start_record_as_test_session(
    name: str,
    description: str = "",
    config: RecordAsTestConfig = None
) -> str
```

**ç¤ºä¾‹:**
```python
session_id = await orchestrator.start_record_as_test_session(
    name="ç”¨æˆ·æ³¨å†Œæµç¨‹æµ‹è¯•",
    description="æµ‹è¯•æ–°ç”¨æˆ·æ³¨å†Œçš„å®Œæ•´æµç¨‹",
    config=custom_config
)
```

#### **æ‰§è¡Œå®Œæ•´å·¥ä½œæµ**
```python
async def execute_complete_workflow() -> RecordAsTestSession
```

**ç¤ºä¾‹:**
```python
# å¼€å§‹å½•åˆ¶
session_id = await orchestrator.start_record_as_test_session("æˆ‘çš„æµ‹è¯•")

# ç”¨æˆ·æ“ä½œ... (ç³»ç»Ÿè‡ªåŠ¨å½•åˆ¶)
await asyncio.sleep(30)  # æ¨¡æ‹Ÿç”¨æˆ·æ“ä½œæ—¶é—´

# æ‰§è¡Œå®Œæ•´å·¥ä½œæµ
session = await orchestrator.execute_complete_workflow()

# æŸ¥çœ‹ç»“æœ
print(f"å½•åˆ¶äº† {session.total_actions} ä¸ªåŠ¨ä½œ")
print(f"ç”Ÿæˆäº† {session.total_components} ä¸ªç»„ä»¶")
print(f"æˆåŠŸç‡: {session.success_rate:.2%}")
```

### **4. ActionRecognitionEngine API**

#### **å¼€å§‹ç›‘æ§ç”¨æˆ·åŠ¨ä½œ**
```python
def start_monitoring(
    callback: Callable[[UserAction], None] = None
) -> None
```

**ç¤ºä¾‹:**
```python
def on_action(action: UserAction):
    print(f"æ£€æµ‹åˆ°åŠ¨ä½œ: {action.action_type} at {action.coordinates}")

engine = ActionRecognitionEngine()
engine.start_monitoring(callback=on_action)

# åœæ­¢ç›‘æ§
engine.stop_monitoring()
```

#### **è·å–åŠ¨ä½œå†å²**
```python
def get_action_history(
    start_time: float = None,
    end_time: float = None,
    action_types: List[ActionType] = None
) -> List[UserAction]
```

**ç¤ºä¾‹:**
```python
# è·å–æœ€è¿‘5åˆ†é’Ÿçš„æ‰€æœ‰ç‚¹å‡»åŠ¨ä½œ
import time
five_minutes_ago = time.time() - 300

actions = engine.get_action_history(
    start_time=five_minutes_ago,
    action_types=[ActionType.CLICK, ActionType.INPUT]
)

for action in actions:
    print(f"{action.action_type}: {action.element_info}")
```

### **5. TestNodeGenerator API**

#### **ä»åŠ¨ä½œç”Ÿæˆæµ‹è¯•æµç¨‹**
```python
async def generate_test_flow_from_actions(
    actions: List[UserAction],
    config: Dict[str, Any] = None
) -> TestFlow
```

**ç¤ºä¾‹:**
```python
# è·å–å½•åˆ¶çš„åŠ¨ä½œ
actions = engine.get_action_history()

# ç”Ÿæˆæµ‹è¯•æµç¨‹
generator = TestNodeGenerator()
test_flow = await generator.generate_test_flow_from_actions(
    actions=actions,
    config={
        "auto_generate_assertions": True,
        "insert_wait_nodes": True,
        "optimize_node_sequence": True
    }
)

print(f"ç”Ÿæˆäº† {len(test_flow.nodes)} ä¸ªæµ‹è¯•èŠ‚ç‚¹")
```

#### **ä¼˜åŒ–æµ‹è¯•æµç¨‹**
```python
async def optimize_test_flow(test_flow: TestFlow) -> TestFlow
```

**ç¤ºä¾‹:**
```python
optimized_flow = await generator.optimize_test_flow(test_flow)
print(f"ä¼˜åŒ–åèŠ‚ç‚¹æ•°: {len(optimized_flow.nodes)}")
```

### **6. AGUIAutoGenerator API**

#### **ä»æµ‹è¯•æµç¨‹ç”Ÿæˆç»„ä»¶**
```python
async def generate_components_from_test_flow(
    test_flow: TestFlow,
    config: Dict[str, Any] = None
) -> AGUITestSuite
```

**ç¤ºä¾‹:**
```python
generator = AGUIAutoGenerator({
    'generate_react': True,
    'generate_vue': True,
    'component_prefix': 'Auto',
    'include_tests': True
})

test_suite = await generator.generate_components_from_test_flow(
    test_flow=test_flow,
    config={
        'output_directory': 'generated_components',
        'include_stories': True
    }
)

print(f"ç”Ÿæˆäº† {len(test_suite.components)} ä¸ªç»„ä»¶")
```

#### **å¯¼å‡ºæµ‹è¯•å¥—ä»¶**
```python
def export_test_suite_to_files(
    test_suite: AGUITestSuite,
    output_directory: str
) -> List[str]
```

**ç¤ºä¾‹:**
```python
file_paths = generator.export_test_suite_to_files(
    test_suite=test_suite,
    output_directory="./output"
)

for path in file_paths:
    print(f"ç”Ÿæˆæ–‡ä»¶: {path}")
```

### **7. PlaybackVerificationEngine API**

#### **éªŒè¯æµ‹è¯•æµç¨‹**
```python
async def verify_test_flow(
    test_flow: TestFlow,
    config: Dict[str, Any] = None
) -> PlaybackSession
```

**ç¤ºä¾‹:**
```python
engine = PlaybackVerificationEngine({
    'continue_on_failure': True,
    'capture_screenshots': True,
    'verification_timeout': 60.0
})

playback_session = await engine.verify_test_flow(
    test_flow=test_flow,
    config={
        'parallel_execution': False,
        'generate_report': True
    }
)

print(f"éªŒè¯ç»“æœ: {playback_session.performance_metrics['success_rate']:.2%}")
```

## ğŸ“‹ **å‘½ä»¤è¡Œæ¥å£ (CLI)**

### **åŸºæœ¬å‘½ä»¤**
```bash
# è¿è¡ŒP0æµ‹è¯•
python -m core.components.stagewise_mcp.test_runner p0

# è¿è¡ŒMCPç»„ä»¶æµ‹è¯•
python -m core.components.stagewise_mcp.test_runner mcp

# è¿è¡ŒUIæµ‹è¯•
python -m core.components.stagewise_mcp.test_runner ui --output ui_report.json

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python -m core.components.stagewise_mcp.test_runner performance --parallel

# è¿è¡ŒæŒ‡å®šæµ‹è¯•å¥—ä»¶
python -m core.components.stagewise_mcp.test_runner suite ui_functionality_tests

# è¿è¡ŒæŒ‡å®šæµ‹è¯•ç”¨ä¾‹
python -m core.components.stagewise_mcp.test_runner case test_login_functionality
```

### **é«˜çº§é€‰é¡¹**
```bash
# ä½¿ç”¨é…ç½®æ–‡ä»¶
python -m core.components.stagewise_mcp.test_runner p0 --config test_config.json

# å¹¶è¡Œæ‰§è¡Œ
python -m core.components.stagewise_mcp.test_runner all --parallel --max-workers 8

# è®¾ç½®è¶…æ—¶å’Œé‡è¯•
python -m core.components.stagewise_mcp.test_runner mcp --timeout 120 --retry 3

# è¯¦ç»†è¾“å‡º
python -m core.components.stagewise_mcp.test_runner ui --verbose --debug
```

## ğŸ¯ **å®é™…ä½¿ç”¨åœºæ™¯**

### **åœºæ™¯1: å¿«é€ŸUIæµ‹è¯•å½•åˆ¶**
```python
async def quick_ui_test_recording():
    """å¿«é€Ÿå½•åˆ¶UIæµ‹è¯•"""
    
    # 1. åˆå§‹åŒ–
    orchestrator = RecordAsTestOrchestrator(RecordAsTestConfig(
        recording_timeout=60.0,
        generate_react_components=True,
        auto_playback_verification=True
    ))
    
    # 2. å¼€å§‹å½•åˆ¶
    session_id = await orchestrator.start_record_as_test_session(
        name="å¿«é€ŸUIæµ‹è¯•",
        description="å½•åˆ¶åŸºæœ¬UIæ“ä½œ"
    )
    
    print("å¼€å§‹å½•åˆ¶ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­è¿›è¡Œæ“ä½œ...")
    
    # 3. ç­‰å¾…ç”¨æˆ·æ“ä½œ
    await asyncio.sleep(30)  # 30ç§’å½•åˆ¶æ—¶é—´
    
    # 4. å®Œæˆå½•åˆ¶å¹¶ç”Ÿæˆ
    session = await orchestrator.execute_complete_workflow()
    
    # 5. è¾“å‡ºç»“æœ
    print(f"å½•åˆ¶å®Œæˆï¼")
    print(f"- åŠ¨ä½œæ•°é‡: {session.total_actions}")
    print(f"- ç”Ÿæˆç»„ä»¶: {session.total_components}")
    print(f"- è¾“å‡ºç›®å½•: {session.output_directory}")
    
    return session

# è¿è¡Œ
session = await quick_ui_test_recording()
```

### **åœºæ™¯2: æ‰¹é‡æµ‹è¯•æ‰§è¡Œ**
```python
async def batch_test_execution():
    """æ‰¹é‡æ‰§è¡Œå¤šä¸ªæµ‹è¯•å¥—ä»¶"""
    
    runner = StagewiseTestRunner("test_config.json")
    
    test_suites = [
        "p0_core_tests",
        "mcp_component_tests", 
        "ui_functionality_tests",
        "performance_tests"
    ]
    
    results = {}
    
    for suite in test_suites:
        print(f"æ‰§è¡Œæµ‹è¯•å¥—ä»¶: {suite}")
        
        session = await runner.run_test_suite(suite)
        results[suite] = {
            "total": session.total_tests,
            "passed": session.passed_tests,
            "failed": session.failed_tests,
            "success_rate": session.passed_tests / session.total_tests
        }
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print("\nğŸ“Š æµ‹è¯•æ±‡æ€»æŠ¥å‘Š:")
    for suite, result in results.items():
        print(f"{suite}: {result['passed']}/{result['total']} "
              f"({result['success_rate']:.1%})")
    
    return results

# è¿è¡Œ
results = await batch_test_execution()
```

### **åœºæ™¯3: è‡ªå®šä¹‰æµ‹è¯•æµç¨‹**
```python
async def custom_test_workflow():
    """è‡ªå®šä¹‰æµ‹è¯•å·¥ä½œæµç¨‹"""
    
    # 1. åŠ¨ä½œè¯†åˆ«
    action_engine = ActionRecognitionEngine()
    action_engine.start_monitoring()
    
    print("è¯·è¿›è¡Œæ“ä½œï¼Œ10ç§’åè‡ªåŠ¨åœæ­¢...")
    await asyncio.sleep(10)
    
    action_engine.stop_monitoring()
    actions = action_engine.get_action_history()
    
    # 2. ç”Ÿæˆæµ‹è¯•èŠ‚ç‚¹
    node_generator = TestNodeGenerator()
    test_flow = await node_generator.generate_test_flow_from_actions(actions)
    
    # 3. ç”ŸæˆAG-UIç»„ä»¶
    ag_ui_generator = AGUIAutoGenerator()
    test_suite = await ag_ui_generator.generate_components_from_test_flow(test_flow)
    
    # 4. éªŒè¯å›æ”¾
    playback_engine = PlaybackVerificationEngine()
    playback_session = await playback_engine.verify_test_flow(test_flow)
    
    # 5. å¯¼å‡ºç»“æœ
    output_files = ag_ui_generator.export_test_suite_to_files(
        test_suite, "custom_output"
    )
    
    print(f"å·¥ä½œæµå®Œæˆï¼ç”Ÿæˆäº† {len(output_files)} ä¸ªæ–‡ä»¶")
    return {
        "actions": len(actions),
        "nodes": len(test_flow.nodes),
        "components": len(test_suite.components),
        "success_rate": playback_session.performance_metrics['success_rate'],
        "output_files": output_files
    }

# è¿è¡Œ
result = await custom_test_workflow()
```

## ğŸ” **é”™è¯¯å¤„ç†å’Œè°ƒè¯•**

### **å¸¸è§é”™è¯¯å¤„ç†**
```python
try:
    session = await orchestrator.start_record_as_test_session("æµ‹è¯•")
except Exception as e:
    logger.error(f"å½•åˆ¶å¯åŠ¨å¤±è´¥: {str(e)}")
    # å¤„ç†é”™è¯¯...

# æ£€æŸ¥ä¼šè¯çŠ¶æ€
if session.status == RecordAsTestStatus.FAILED:
    print(f"å½•åˆ¶å¤±è´¥ï¼Œé”™è¯¯: {session.errors}")

# éªŒè¯é…ç½®
config = RecordAsTestConfig()
if not config.output_directory:
    config.output_directory = "default_output"
```

### **è°ƒè¯•æŠ€å·§**
```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
for file_path in session.component_files:
    if Path(file_path).exists():
        print(f"âœ… æ–‡ä»¶å­˜åœ¨: {file_path}")
    else:
        print(f"âŒ æ–‡ä»¶ç¼ºå¤±: {file_path}")

# æŸ¥çœ‹æ€§èƒ½æŒ‡æ ‡
metrics = playback_session.performance_metrics
print(f"å¹³å‡èŠ‚ç‚¹æ‰§è¡Œæ—¶é—´: {metrics['average_node_time']:.2f}s")
print(f"æ€»æ‰§è¡Œæ—¶é—´: {metrics['total_duration']:.2f}s")
```

## ğŸ“Š **æ€§èƒ½ä¼˜åŒ–å»ºè®®**

### **å½•åˆ¶æ€§èƒ½ä¼˜åŒ–**
```python
# ä¼˜åŒ–å½•åˆ¶é…ç½®
config = RecordAsTestConfig(
    recording_timeout=120.0,  # é€‚å½“çš„è¶…æ—¶æ—¶é—´
    min_actions_required=5,   # æœ€å°‘åŠ¨ä½œæ•°é‡
    auto_start_recording=True # è‡ªåŠ¨å¼€å§‹å½•åˆ¶
)

# å‡å°‘æˆªå›¾é¢‘ç‡
action_engine = ActionRecognitionEngine({
    'screenshot_interval': 2.0,  # æ¯2ç§’æˆªå›¾ä¸€æ¬¡
    'action_buffer_size': 1000   # å¢å¤§ç¼“å†²åŒº
})
```

### **æµ‹è¯•æ‰§è¡Œä¼˜åŒ–**
```python
# å¹¶è¡Œæ‰§è¡Œæµ‹è¯•
runner = StagewiseTestRunner({
    'parallel': True,
    'max_workers': 4,
    'timeout': 60
})

# ä¼˜åŒ–æµ‹è¯•æµç¨‹
optimized_flow = await node_generator.optimize_test_flow(test_flow)
```

è¿™ä¸ªAPIæ–‡æ¡£æä¾›äº†Stagewiseæµ‹è¯•æ¡†æ¶çš„å®Œæ•´ä½¿ç”¨æŒ‡å—ï¼ŒåŒ…æ‹¬æ‰€æœ‰æ ¸å¿ƒæ¥å£ã€å®é™…ä½¿ç”¨åœºæ™¯å’Œæœ€ä½³å®è·µå»ºè®®ã€‚

