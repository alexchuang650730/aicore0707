#!/usr/bin/env python3
"""
PowerAutomation 4.1 Agent Zeroé›†æˆç»„ä»¶

Agent Zeroæ˜¯ä¸€ä¸ªæœ‰æœºæ™ºèƒ½ä½“æ¡†æ¶ï¼Œå…·æœ‰è‡ªå­¦ä¹ èƒ½åŠ›å’ŒåŠ¨æ€é€‚åº”æ€§ã€‚
æœ¬æ¨¡å—å®ç°äº†Agent Zeroä¸PowerAutomation + ClaudEditorçš„æ·±åº¦é›†æˆã€‚

Agent Zeroæ ¸å¿ƒç‰¹æ€§ï¼š
1. æœ‰æœºæ™ºèƒ½ä½“æ¶æ„ - è‡ªç„¶æ¼”åŒ–çš„æ™ºèƒ½ä½“ç³»ç»Ÿ
2. è‡ªå­¦ä¹ èƒ½åŠ› - ä»äº¤äº’ä¸­æŒç»­å­¦ä¹ å’Œæ”¹è¿›
3. åŠ¨æ€é€‚åº”æ€§ - æ ¹æ®ç¯å¢ƒå˜åŒ–è‡ªåŠ¨è°ƒæ•´è¡Œä¸º
4. å¤šæ™ºèƒ½ä½“åä½œ - æ”¯æŒæ™ºèƒ½ä½“é—´çš„åä½œå’Œé€šä¿¡
5. çŸ¥è¯†å›¾è°±æ„å»º - è‡ªåŠ¨æ„å»ºå’Œç»´æŠ¤çŸ¥è¯†ç½‘ç»œ

ä½œè€…: PowerAutomation Team
ç‰ˆæœ¬: 4.1
æ—¥æœŸ: 2025-01-07
"""

import asyncio
import json
import time
import uuid
import random
import math
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple, Union, Callable
from dataclasses import dataclass, field, asdict
from enum import Enum
import logging
from pathlib import Path
import networkx as nx

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AgentState(Enum):
    """æ™ºèƒ½ä½“çŠ¶æ€"""
    INITIALIZING = "initializing"
    ACTIVE = "active"
    LEARNING = "learning"
    ADAPTING = "adapting"
    COLLABORATING = "collaborating"
    DORMANT = "dormant"
    ERROR = "error"

class LearningMode(Enum):
    """å­¦ä¹ æ¨¡å¼"""
    SUPERVISED = "supervised"        # ç›‘ç£å­¦ä¹ 
    UNSUPERVISED = "unsupervised"   # æ— ç›‘ç£å­¦ä¹ 
    REINFORCEMENT = "reinforcement" # å¼ºåŒ–å­¦ä¹ 
    IMITATION = "imitation"         # æ¨¡ä»¿å­¦ä¹ 
    SELF_SUPERVISED = "self_supervised" # è‡ªç›‘ç£å­¦ä¹ 

class AdaptationStrategy(Enum):
    """é€‚åº”ç­–ç•¥"""
    CONSERVATIVE = "conservative"    # ä¿å®ˆç­–ç•¥
    AGGRESSIVE = "aggressive"       # æ¿€è¿›ç­–ç•¥
    BALANCED = "balanced"           # å¹³è¡¡ç­–ç•¥
    EXPLORATORY = "exploratory"     # æ¢ç´¢ç­–ç•¥
    EXPLOITATIVE = "exploitative"   # åˆ©ç”¨ç­–ç•¥

@dataclass
class AgentCapability:
    """æ™ºèƒ½ä½“èƒ½åŠ›"""
    capability_id: str
    name: str
    description: str
    proficiency_level: float  # 0.0 - 1.0
    learning_rate: float
    adaptation_speed: float
    usage_count: int = 0
    success_rate: float = 0.0
    last_used: Optional[datetime] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def update_proficiency(self, success: bool, learning_rate: float = None):
        """æ›´æ–°èƒ½åŠ›ç†Ÿç»ƒåº¦"""
        if learning_rate is None:
            learning_rate = self.learning_rate
        
        self.usage_count += 1
        
        # æ›´æ–°æˆåŠŸç‡
        if self.usage_count == 1:
            self.success_rate = 1.0 if success else 0.0
        else:
            self.success_rate = ((self.success_rate * (self.usage_count - 1)) + 
                               (1.0 if success else 0.0)) / self.usage_count
        
        # æ›´æ–°ç†Ÿç»ƒåº¦
        if success:
            improvement = learning_rate * (1.0 - self.proficiency_level)
            self.proficiency_level = min(1.0, self.proficiency_level + improvement)
        else:
            degradation = learning_rate * 0.1  # å¤±è´¥æ—¶è½»å¾®é™ä½
            self.proficiency_level = max(0.0, self.proficiency_level - degradation)
        
        self.last_used = datetime.now()

@dataclass
class LearningExperience:
    """å­¦ä¹ ç»éªŒ"""
    experience_id: str
    agent_id: str
    context: Dict[str, Any]
    action_taken: str
    outcome: Dict[str, Any]
    success: bool
    reward: float
    learning_mode: LearningMode
    timestamp: datetime
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class KnowledgeNode:
    """çŸ¥è¯†èŠ‚ç‚¹"""
    node_id: str
    content: Dict[str, Any]
    node_type: str  # concept, fact, rule, pattern
    confidence: float
    connections: List[str] = field(default_factory=list)
    creation_time: datetime = field(default_factory=datetime.now)
    last_accessed: datetime = field(default_factory=datetime.now)
    access_count: int = 0

class OrganicAgent:
    """æœ‰æœºæ™ºèƒ½ä½“"""
    
    def __init__(self, agent_id: str, agent_type: str = "general", 
                 initial_capabilities: List[str] = None):
        """åˆå§‹åŒ–æœ‰æœºæ™ºèƒ½ä½“"""
        self.agent_id = agent_id
        self.agent_type = agent_type
        self.state = AgentState.INITIALIZING
        self.learning_mode = LearningMode.SELF_SUPERVISED
        self.adaptation_strategy = AdaptationStrategy.BALANCED
        
        # æ™ºèƒ½ä½“èƒ½åŠ›
        self.capabilities: Dict[str, AgentCapability] = {}
        self._initialize_capabilities(initial_capabilities or [])
        
        # å­¦ä¹ ç³»ç»Ÿ
        self.experiences: List[LearningExperience] = []
        self.knowledge_graph = nx.DiGraph()
        self.learning_rate = 0.1
        self.adaptation_threshold = 0.7
        
        # åä½œç³»ç»Ÿ
        self.collaborators: Dict[str, 'OrganicAgent'] = {}
        self.communication_history: List[Dict[str, Any]] = []
        
        # æ€§èƒ½æŒ‡æ ‡
        self.performance_metrics = {
            "total_tasks": 0,
            "successful_tasks": 0,
            "learning_episodes": 0,
            "adaptation_events": 0,
            "collaboration_sessions": 0,
            "knowledge_nodes": 0
        }
        
        # è‡ªæˆ‘è¯„ä¼°
        self.self_assessment = {
            "overall_competence": 0.5,
            "learning_efficiency": 0.5,
            "adaptation_speed": 0.5,
            "collaboration_ability": 0.5
        }
        
        self.state = AgentState.ACTIVE
        logger.info(f"æœ‰æœºæ™ºèƒ½ä½“ {agent_id} åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_capabilities(self, capability_names: List[str]):
        """åˆå§‹åŒ–æ™ºèƒ½ä½“èƒ½åŠ›"""
        default_capabilities = [
            "problem_solving", "pattern_recognition", "decision_making",
            "communication", "learning", "adaptation"
        ]
        
        all_capabilities = list(set(default_capabilities + capability_names))
        
        for cap_name in all_capabilities:
            capability = AgentCapability(
                capability_id=str(uuid.uuid4()),
                name=cap_name,
                description=f"æ™ºèƒ½ä½“çš„{cap_name}èƒ½åŠ›",
                proficiency_level=random.uniform(0.3, 0.7),  # éšæœºåˆå§‹ç†Ÿç»ƒåº¦
                learning_rate=random.uniform(0.05, 0.15),
                adaptation_speed=random.uniform(0.1, 0.3)
            )
            self.capabilities[cap_name] = capability
    
    async def execute_task(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œä»»åŠ¡"""
        self.state = AgentState.ACTIVE
        start_time = time.time()
        
        # åˆ†æä»»åŠ¡éœ€æ±‚
        required_capabilities = self._analyze_task_requirements(task)
        
        # è¯„ä¼°è‡ªèº«èƒ½åŠ›
        capability_assessment = self._assess_capabilities(required_capabilities)
        
        # å†³å®šæ‰§è¡Œç­–ç•¥
        execution_strategy = self._determine_execution_strategy(
            task, capability_assessment
        )
        
        # æ‰§è¡Œä»»åŠ¡
        try:
            result = await self._execute_with_strategy(task, execution_strategy)
            success = result.get("success", False)
            
            # è®°å½•å­¦ä¹ ç»éªŒ
            await self._record_experience(task, result, success)
            
            # æ›´æ–°èƒ½åŠ›
            self._update_capabilities(required_capabilities, success)
            
            # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
            self.performance_metrics["total_tasks"] += 1
            if success:
                self.performance_metrics["successful_tasks"] += 1
            
            # è§¦å‘è‡ªé€‚åº”
            if self._should_adapt():
                await self._trigger_adaptation()
            
            execution_time = time.time() - start_time
            
            return {
                "success": success,
                "result": result,
                "execution_time": execution_time,
                "capabilities_used": required_capabilities,
                "learning_occurred": True,
                "agent_state": self.state.value
            }
            
        except Exception as e:
            logger.error(f"æ™ºèƒ½ä½“ {self.agent_id} æ‰§è¡Œä»»åŠ¡å¤±è´¥: {e}")
            await self._record_experience(task, {"error": str(e)}, False)
            
            return {
                "success": False,
                "error": str(e),
                "execution_time": time.time() - start_time,
                "agent_state": AgentState.ERROR.value
            }
    
    def _analyze_task_requirements(self, task: Dict[str, Any]) -> List[str]:
        """åˆ†æä»»åŠ¡éœ€æ±‚"""
        task_type = task.get("type", "general")
        task_complexity = task.get("complexity", "medium")
        
        # åŸºäºä»»åŠ¡ç±»å‹æ˜ å°„æ‰€éœ€èƒ½åŠ›
        capability_mapping = {
            "code_analysis": ["problem_solving", "pattern_recognition"],
            "code_generation": ["problem_solving", "decision_making"],
            "debugging": ["problem_solving", "pattern_recognition", "decision_making"],
            "optimization": ["problem_solving", "pattern_recognition"],
            "collaboration": ["communication", "decision_making"],
            "learning": ["learning", "adaptation"],
            "general": ["problem_solving", "decision_making"]
        }
        
        required_caps = capability_mapping.get(task_type, ["problem_solving"])
        
        # æ ¹æ®å¤æ‚åº¦è°ƒæ•´
        if task_complexity == "high":
            required_caps.extend(["adaptation", "learning"])
        
        return list(set(required_caps))
    
    def _assess_capabilities(self, required_capabilities: List[str]) -> Dict[str, float]:
        """è¯„ä¼°èƒ½åŠ›åŒ¹é…åº¦"""
        assessment = {}
        
        for cap_name in required_capabilities:
            if cap_name in self.capabilities:
                capability = self.capabilities[cap_name]
                # ç»¼åˆè€ƒè™‘ç†Ÿç»ƒåº¦å’ŒæˆåŠŸç‡
                score = (capability.proficiency_level * 0.7 + 
                        capability.success_rate * 0.3)
                assessment[cap_name] = score
            else:
                # ç¼ºå¤±èƒ½åŠ›ï¼Œéœ€è¦å­¦ä¹ 
                assessment[cap_name] = 0.0
        
        return assessment
    
    def _determine_execution_strategy(self, task: Dict[str, Any], 
                                    assessment: Dict[str, float]) -> Dict[str, Any]:
        """ç¡®å®šæ‰§è¡Œç­–ç•¥"""
        avg_capability = sum(assessment.values()) / len(assessment) if assessment else 0.0
        
        strategy = {
            "approach": "direct",
            "confidence": avg_capability,
            "need_collaboration": False,
            "need_learning": False
        }
        
        # å¦‚æœèƒ½åŠ›ä¸è¶³ï¼Œè€ƒè™‘åä½œæˆ–å­¦ä¹ 
        if avg_capability < 0.5:
            strategy["need_collaboration"] = True
            strategy["approach"] = "collaborative"
        
        if avg_capability < 0.3:
            strategy["need_learning"] = True
            strategy["approach"] = "learning_based"
        
        # æ ¹æ®é€‚åº”ç­–ç•¥è°ƒæ•´
        if self.adaptation_strategy == AdaptationStrategy.EXPLORATORY:
            strategy["exploration_factor"] = 0.3
        elif self.adaptation_strategy == AdaptationStrategy.CONSERVATIVE:
            strategy["risk_tolerance"] = 0.2
        
        return strategy
    
    async def _execute_with_strategy(self, task: Dict[str, Any], 
                                   strategy: Dict[str, Any]) -> Dict[str, Any]:
        """æ ¹æ®ç­–ç•¥æ‰§è¡Œä»»åŠ¡"""
        approach = strategy["approach"]
        
        if approach == "collaborative" and strategy.get("need_collaboration"):
            return await self._execute_collaboratively(task)
        elif approach == "learning_based" and strategy.get("need_learning"):
            return await self._execute_with_learning(task)
        else:
            return await self._execute_directly(task)
    
    async def _execute_directly(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """ç›´æ¥æ‰§è¡Œä»»åŠ¡"""
        # æ¨¡æ‹Ÿä»»åŠ¡æ‰§è¡Œ
        task_complexity = task.get("complexity", "medium")
        
        # åŸºäºèƒ½åŠ›è®¡ç®—æˆåŠŸæ¦‚ç‡
        required_caps = self._analyze_task_requirements(task)
        capability_scores = [
            self.capabilities[cap].proficiency_level 
            for cap in required_caps if cap in self.capabilities
        ]
        
        avg_capability = sum(capability_scores) / len(capability_scores) if capability_scores else 0.5
        
        # å¤æ‚åº¦å½±å“æˆåŠŸç‡
        complexity_factor = {"low": 1.2, "medium": 1.0, "high": 0.8}.get(task_complexity, 1.0)
        success_probability = min(1.0, avg_capability * complexity_factor)
        
        success = random.random() < success_probability
        
        # æ¨¡æ‹Ÿæ‰§è¡Œæ—¶é—´
        execution_time = random.uniform(1.0, 5.0)
        await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¼‚æ­¥æ‰§è¡Œ
        
        result = {
            "success": success,
            "output": f"ä»»åŠ¡æ‰§è¡Œ{'æˆåŠŸ' if success else 'å¤±è´¥'}",
            "execution_method": "direct",
            "capability_utilization": avg_capability,
            "execution_time": execution_time
        }
        
        return result
    
    async def _execute_collaboratively(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """åä½œæ‰§è¡Œä»»åŠ¡"""
        # å¯»æ‰¾åˆé€‚çš„åä½œè€…
        collaborator = self._find_best_collaborator(task)
        
        if collaborator:
            # ä¸åä½œè€…å…±åŒæ‰§è¡Œ
            self.performance_metrics["collaboration_sessions"] += 1
            
            # æ¨¡æ‹Ÿåä½œæ‰§è¡Œ
            my_contribution = await self._execute_directly(task)
            collaborator_contribution = await collaborator._execute_directly(task)
            
            # åˆå¹¶ç»“æœ
            combined_success_rate = (
                (my_contribution.get("capability_utilization", 0.5) + 
                 collaborator_contribution.get("capability_utilization", 0.5)) / 2
            )
            
            success = random.random() < min(1.0, combined_success_rate * 1.3)  # åä½œåŠ æˆ
            
            result = {
                "success": success,
                "output": f"åä½œä»»åŠ¡æ‰§è¡Œ{'æˆåŠŸ' if success else 'å¤±è´¥'}",
                "execution_method": "collaborative",
                "collaborator": collaborator.agent_id,
                "my_contribution": my_contribution,
                "collaborator_contribution": collaborator_contribution,
                "collaboration_bonus": 0.3
            }
            
            # è®°å½•åä½œå†å²
            self.communication_history.append({
                "type": "collaboration",
                "partner": collaborator.agent_id,
                "task": task,
                "result": result,
                "timestamp": datetime.now()
            })
            
            return result
        else:
            # æ²¡æœ‰åˆé€‚çš„åä½œè€…ï¼Œé™çº§ä¸ºç›´æ¥æ‰§è¡Œ
            return await self._execute_directly(task)
    
    async def _execute_with_learning(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """å¸¦å­¦ä¹ çš„æ‰§è¡Œä»»åŠ¡"""
        self.state = AgentState.LEARNING
        
        # å…ˆå°è¯•ç›´æ¥æ‰§è¡Œ
        initial_result = await self._execute_directly(task)
        
        # å¦‚æœå¤±è´¥ï¼Œè¿›è¡Œå­¦ä¹ 
        if not initial_result.get("success", False):
            learning_result = await self._learn_from_failure(task, initial_result)
            
            # å†æ¬¡å°è¯•æ‰§è¡Œ
            if learning_result.get("learning_success", False):
                retry_result = await self._execute_directly(task)
                
                result = {
                    "success": retry_result.get("success", False),
                    "output": f"å­¦ä¹ åä»»åŠ¡æ‰§è¡Œ{'æˆåŠŸ' if retry_result.get('success') else 'å¤±è´¥'}",
                    "execution_method": "learning_based",
                    "initial_attempt": initial_result,
                    "learning_phase": learning_result,
                    "retry_attempt": retry_result,
                    "learning_improvement": True
                }
                
                self.performance_metrics["learning_episodes"] += 1
                return result
        
        return initial_result
    
    def _find_best_collaborator(self, task: Dict[str, Any]) -> Optional['OrganicAgent']:
        """å¯»æ‰¾æœ€ä½³åä½œè€…"""
        if not self.collaborators:
            return None
        
        required_capabilities = self._analyze_task_requirements(task)
        best_collaborator = None
        best_score = 0.0
        
        for collaborator in self.collaborators.values():
            # è¯„ä¼°åä½œè€…çš„èƒ½åŠ›åŒ¹é…åº¦
            score = 0.0
            for cap_name in required_capabilities:
                if cap_name in collaborator.capabilities:
                    score += collaborator.capabilities[cap_name].proficiency_level
            
            avg_score = score / len(required_capabilities) if required_capabilities else 0.0
            
            if avg_score > best_score:
                best_score = avg_score
                best_collaborator = collaborator
        
        return best_collaborator if best_score > 0.6 else None
    
    async def _learn_from_failure(self, task: Dict[str, Any], 
                                failure_result: Dict[str, Any]) -> Dict[str, Any]:
        """ä»å¤±è´¥ä¸­å­¦ä¹ """
        required_capabilities = self._analyze_task_requirements(task)
        
        # åˆ†æå¤±è´¥åŸå› 
        failure_analysis = self._analyze_failure(task, failure_result, required_capabilities)
        
        # æ›´æ–°å­¦ä¹ ç‡
        learning_improvements = {}
        for cap_name in required_capabilities:
            if cap_name in self.capabilities:
                capability = self.capabilities[cap_name]
                # å¢åŠ å­¦ä¹ ç‡ä»¥å¿«é€Ÿæ”¹è¿›
                old_proficiency = capability.proficiency_level
                capability.learning_rate *= 1.2  # å¢åŠ å­¦ä¹ ç‡
                capability.proficiency_level = min(1.0, capability.proficiency_level + 0.1)
                
                learning_improvements[cap_name] = {
                    "old_proficiency": old_proficiency,
                    "new_proficiency": capability.proficiency_level,
                    "learning_rate_boost": 1.2
                }
            else:
                # åˆ›å»ºæ–°èƒ½åŠ›
                new_capability = AgentCapability(
                    capability_id=str(uuid.uuid4()),
                    name=cap_name,
                    description=f"ä»å¤±è´¥ä¸­å­¦ä¹ çš„{cap_name}èƒ½åŠ›",
                    proficiency_level=0.2,  # ä»ä½æ°´å¹³å¼€å§‹
                    learning_rate=0.2,     # é«˜å­¦ä¹ ç‡
                    adaptation_speed=0.3
                )
                self.capabilities[cap_name] = new_capability
                
                learning_improvements[cap_name] = {
                    "new_capability": True,
                    "initial_proficiency": 0.2
                }
        
        # æ›´æ–°çŸ¥è¯†å›¾è°±
        await self._update_knowledge_graph(task, failure_result, failure_analysis)
        
        return {
            "learning_success": True,
            "failure_analysis": failure_analysis,
            "capability_improvements": learning_improvements,
            "knowledge_updated": True
        }
    
    def _analyze_failure(self, task: Dict[str, Any], failure_result: Dict[str, Any], 
                        required_capabilities: List[str]) -> Dict[str, Any]:
        """åˆ†æå¤±è´¥åŸå› """
        analysis = {
            "primary_cause": "capability_insufficient",
            "capability_gaps": [],
            "complexity_mismatch": False,
            "resource_constraints": False
        }
        
        # åˆ†æèƒ½åŠ›ç¼ºå£
        for cap_name in required_capabilities:
            if cap_name not in self.capabilities:
                analysis["capability_gaps"].append({
                    "capability": cap_name,
                    "status": "missing"
                })
            elif self.capabilities[cap_name].proficiency_level < 0.5:
                analysis["capability_gaps"].append({
                    "capability": cap_name,
                    "status": "insufficient",
                    "current_level": self.capabilities[cap_name].proficiency_level
                })
        
        # åˆ†æå¤æ‚åº¦åŒ¹é…
        task_complexity = task.get("complexity", "medium")
        if task_complexity == "high" and self.self_assessment["overall_competence"] < 0.7:
            analysis["complexity_mismatch"] = True
        
        return analysis
    
    async def _update_knowledge_graph(self, task: Dict[str, Any], 
                                    result: Dict[str, Any], 
                                    analysis: Dict[str, Any]):
        """æ›´æ–°çŸ¥è¯†å›¾è°±"""
        # åˆ›å»ºä»»åŠ¡èŠ‚ç‚¹
        task_node = KnowledgeNode(
            node_id=f"task_{uuid.uuid4()}",
            content={
                "task_type": task.get("type", "general"),
                "complexity": task.get("complexity", "medium"),
                "requirements": task
            },
            node_type="task",
            confidence=0.8
        )
        
        # åˆ›å»ºç»“æœèŠ‚ç‚¹
        result_node = KnowledgeNode(
            node_id=f"result_{uuid.uuid4()}",
            content={
                "success": result.get("success", False),
                "execution_method": result.get("execution_method", "direct"),
                "analysis": analysis
            },
            node_type="outcome",
            confidence=0.9
        )
        
        # æ·»åŠ åˆ°çŸ¥è¯†å›¾è°±
        self.knowledge_graph.add_node(task_node.node_id, **asdict(task_node))
        self.knowledge_graph.add_node(result_node.node_id, **asdict(result_node))
        self.knowledge_graph.add_edge(task_node.node_id, result_node.node_id, 
                                    relation="produces")
        
        self.performance_metrics["knowledge_nodes"] += 2
    
    async def _record_experience(self, task: Dict[str, Any], 
                               result: Dict[str, Any], success: bool):
        """è®°å½•å­¦ä¹ ç»éªŒ"""
        experience = LearningExperience(
            experience_id=str(uuid.uuid4()),
            agent_id=self.agent_id,
            context=task,
            action_taken=result.get("execution_method", "direct"),
            outcome=result,
            success=success,
            reward=1.0 if success else -0.5,
            learning_mode=self.learning_mode,
            timestamp=datetime.now()
        )
        
        self.experiences.append(experience)
        
        # é™åˆ¶ç»éªŒæ•°é‡
        if len(self.experiences) > 1000:
            self.experiences = self.experiences[-800:]  # ä¿ç•™æœ€è¿‘800ä¸ªç»éªŒ
    
    def _update_capabilities(self, required_capabilities: List[str], success: bool):
        """æ›´æ–°èƒ½åŠ›"""
        for cap_name in required_capabilities:
            if cap_name in self.capabilities:
                self.capabilities[cap_name].update_proficiency(success)
    
    def _should_adapt(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦é€‚åº”"""
        # åŸºäºæœ€è¿‘çš„æˆåŠŸç‡å†³å®šæ˜¯å¦é€‚åº”
        recent_experiences = self.experiences[-10:] if len(self.experiences) >= 10 else self.experiences
        
        if not recent_experiences:
            return False
        
        recent_success_rate = sum(1 for exp in recent_experiences if exp.success) / len(recent_experiences)
        
        return recent_success_rate < self.adaptation_threshold
    
    async def _trigger_adaptation(self):
        """è§¦å‘é€‚åº”"""
        self.state = AgentState.ADAPTING
        
        # åˆ†ææœ€è¿‘çš„è¡¨ç°
        performance_analysis = self._analyze_recent_performance()
        
        # è°ƒæ•´å­¦ä¹ ç­–ç•¥
        if performance_analysis["success_rate"] < 0.3:
            self.learning_mode = LearningMode.REINFORCEMENT
            self.adaptation_strategy = AdaptationStrategy.EXPLORATORY
        elif performance_analysis["success_rate"] < 0.6:
            self.learning_mode = LearningMode.SELF_SUPERVISED
            self.adaptation_strategy = AdaptationStrategy.BALANCED
        else:
            self.adaptation_strategy = AdaptationStrategy.EXPLOITATIVE
        
        # è°ƒæ•´èƒ½åŠ›å‚æ•°
        for capability in self.capabilities.values():
            if capability.success_rate < 0.5:
                capability.learning_rate *= 1.1  # å¢åŠ å­¦ä¹ ç‡
            capability.adaptation_speed *= 1.05
        
        # æ›´æ–°è‡ªæˆ‘è¯„ä¼°
        self._update_self_assessment()
        
        self.performance_metrics["adaptation_events"] += 1
        self.state = AgentState.ACTIVE
        
        logger.info(f"æ™ºèƒ½ä½“ {self.agent_id} å®Œæˆé€‚åº”è°ƒæ•´")
    
    def _analyze_recent_performance(self) -> Dict[str, Any]:
        """åˆ†ææœ€è¿‘è¡¨ç°"""
        recent_experiences = self.experiences[-20:] if len(self.experiences) >= 20 else self.experiences
        
        if not recent_experiences:
            return {"success_rate": 0.5, "trend": "stable"}
        
        success_rate = sum(1 for exp in recent_experiences if exp.success) / len(recent_experiences)
        
        # åˆ†æè¶‹åŠ¿
        if len(recent_experiences) >= 10:
            first_half = recent_experiences[:len(recent_experiences)//2]
            second_half = recent_experiences[len(recent_experiences)//2:]
            
            first_half_rate = sum(1 for exp in first_half if exp.success) / len(first_half)
            second_half_rate = sum(1 for exp in second_half if exp.success) / len(second_half)
            
            if second_half_rate > first_half_rate + 0.1:
                trend = "improving"
            elif second_half_rate < first_half_rate - 0.1:
                trend = "declining"
            else:
                trend = "stable"
        else:
            trend = "insufficient_data"
        
        return {
            "success_rate": success_rate,
            "trend": trend,
            "total_experiences": len(recent_experiences)
        }
    
    def _update_self_assessment(self):
        """æ›´æ–°è‡ªæˆ‘è¯„ä¼°"""
        # è®¡ç®—æ•´ä½“èƒ½åŠ›
        if self.capabilities:
            avg_proficiency = sum(cap.proficiency_level for cap in self.capabilities.values()) / len(self.capabilities)
            self.self_assessment["overall_competence"] = avg_proficiency
        
        # è®¡ç®—å­¦ä¹ æ•ˆç‡
        if self.experiences:
            recent_learning = [exp for exp in self.experiences[-50:] if exp.learning_mode != LearningMode.SUPERVISED]
            if recent_learning:
                learning_success_rate = sum(1 for exp in recent_learning if exp.success) / len(recent_learning)
                self.self_assessment["learning_efficiency"] = learning_success_rate
        
        # è®¡ç®—é€‚åº”é€Ÿåº¦
        adaptation_score = min(1.0, self.performance_metrics["adaptation_events"] / max(1, self.performance_metrics["total_tasks"]))
        self.self_assessment["adaptation_speed"] = adaptation_score
        
        # è®¡ç®—åä½œèƒ½åŠ›
        if self.performance_metrics["collaboration_sessions"] > 0:
            collaboration_score = self.performance_metrics["collaboration_sessions"] / max(1, self.performance_metrics["total_tasks"])
            self.self_assessment["collaboration_ability"] = min(1.0, collaboration_score)
    
    async def add_collaborator(self, collaborator: 'OrganicAgent'):
        """æ·»åŠ åä½œè€…"""
        self.collaborators[collaborator.agent_id] = collaborator
        collaborator.collaborators[self.agent_id] = self
        
        logger.info(f"æ™ºèƒ½ä½“ {self.agent_id} ä¸ {collaborator.agent_id} å»ºç«‹åä½œå…³ç³»")
    
    async def communicate(self, target_agent_id: str, message: Dict[str, Any]) -> Dict[str, Any]:
        """ä¸å…¶ä»–æ™ºèƒ½ä½“é€šä¿¡"""
        if target_agent_id in self.collaborators:
            target_agent = self.collaborators[target_agent_id]
            
            # è®°å½•é€šä¿¡
            communication_record = {
                "type": "message",
                "from": self.agent_id,
                "to": target_agent_id,
                "message": message,
                "timestamp": datetime.now()
            }
            
            self.communication_history.append(communication_record)
            target_agent.communication_history.append(communication_record)
            
            # æ¨¡æ‹Ÿå“åº”
            response = await target_agent._process_communication(self.agent_id, message)
            
            return response
        else:
            return {"error": "ç›®æ ‡æ™ºèƒ½ä½“ä¸åœ¨åä½œåˆ—è¡¨ä¸­"}
    
    async def _process_communication(self, sender_id: str, message: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æ¥è‡ªå…¶ä»–æ™ºèƒ½ä½“çš„é€šä¿¡"""
        message_type = message.get("type", "general")
        
        if message_type == "capability_inquiry":
            # è¿”å›èƒ½åŠ›ä¿¡æ¯
            return {
                "type": "capability_response",
                "capabilities": {
                    name: {
                        "proficiency": cap.proficiency_level,
                        "success_rate": cap.success_rate
                    }
                    for name, cap in self.capabilities.items()
                }
            }
        elif message_type == "collaboration_request":
            # è¯„ä¼°æ˜¯å¦æ¥å—åä½œè¯·æ±‚
            task = message.get("task", {})
            my_assessment = self._assess_capabilities(self._analyze_task_requirements(task))
            avg_capability = sum(my_assessment.values()) / len(my_assessment) if my_assessment else 0.0
            
            accept = avg_capability > 0.4  # å¦‚æœæœ‰ä¸€å®šèƒ½åŠ›å°±æ¥å—
            
            return {
                "type": "collaboration_response",
                "accept": accept,
                "capability_assessment": my_assessment
            }
        else:
            return {
                "type": "general_response",
                "message": f"æ”¶åˆ°æ¥è‡ª {sender_id} çš„æ¶ˆæ¯"
            }
    
    def get_agent_status(self) -> Dict[str, Any]:
        """è·å–æ™ºèƒ½ä½“çŠ¶æ€"""
        return {
            "agent_id": self.agent_id,
            "agent_type": self.agent_type,
            "state": self.state.value,
            "learning_mode": self.learning_mode.value,
            "adaptation_strategy": self.adaptation_strategy.value,
            "capabilities": {
                name: {
                    "proficiency": cap.proficiency_level,
                    "success_rate": cap.success_rate,
                    "usage_count": cap.usage_count
                }
                for name, cap in self.capabilities.items()
            },
            "performance_metrics": self.performance_metrics,
            "self_assessment": self.self_assessment,
            "collaborators": list(self.collaborators.keys()),
            "knowledge_graph_size": self.knowledge_graph.number_of_nodes(),
            "experience_count": len(self.experiences)
        }

class AgentZeroIntegration:
    """Agent Zeroä¸PowerAutomationé›†æˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–Agent Zeroé›†æˆ"""
        self.agents: Dict[str, OrganicAgent] = {}
        self.agent_registry = {}
        self.task_queue = asyncio.Queue()
        self.integration_stats = {
            "total_agents": 0,
            "active_agents": 0,
            "completed_tasks": 0,
            "collaboration_events": 0,
            "learning_events": 0,
            "adaptation_events": 0
        }
        
        # åˆ›å»ºé»˜è®¤æ™ºèƒ½ä½“
        asyncio.create_task(self._initialize_default_agents())
        
        logger.info("Agent Zeroé›†æˆåˆå§‹åŒ–å®Œæˆ")
    
    async def _initialize_default_agents(self):
        """åˆå§‹åŒ–é»˜è®¤æ™ºèƒ½ä½“"""
        # åˆ›å»ºä¸“ä¸šæ™ºèƒ½ä½“
        agents_config = [
            {
                "agent_id": "code_analyst",
                "agent_type": "code_analysis",
                "capabilities": ["code_analysis", "pattern_recognition", "problem_solving"]
            },
            {
                "agent_id": "code_generator",
                "agent_type": "code_generation",
                "capabilities": ["code_generation", "problem_solving", "decision_making"]
            },
            {
                "agent_id": "debugger",
                "agent_type": "debugging",
                "capabilities": ["debugging", "problem_solving", "pattern_recognition"]
            },
            {
                "agent_id": "optimizer",
                "agent_type": "optimization",
                "capabilities": ["optimization", "performance_analysis", "problem_solving"]
            },
            {
                "agent_id": "collaborator",
                "agent_type": "collaboration",
                "capabilities": ["communication", "coordination", "decision_making"]
            }
        ]
        
        for config in agents_config:
            agent = OrganicAgent(
                agent_id=config["agent_id"],
                agent_type=config["agent_type"],
                initial_capabilities=config["capabilities"]
            )
            
            await self.register_agent(agent)
        
        # å»ºç«‹åä½œå…³ç³»
        await self._establish_collaborations()
    
    async def _establish_collaborations(self):
        """å»ºç«‹æ™ºèƒ½ä½“é—´çš„åä½œå…³ç³»"""
        agent_list = list(self.agents.values())
        
        # æ¯ä¸ªæ™ºèƒ½ä½“ä¸å…¶ä»–æ™ºèƒ½ä½“å»ºç«‹åä½œå…³ç³»
        for i, agent1 in enumerate(agent_list):
            for j, agent2 in enumerate(agent_list):
                if i != j:
                    await agent1.add_collaborator(agent2)
    
    async def register_agent(self, agent: OrganicAgent):
        """æ³¨å†Œæ™ºèƒ½ä½“"""
        self.agents[agent.agent_id] = agent
        self.agent_registry[agent.agent_id] = {
            "agent_type": agent.agent_type,
            "capabilities": list(agent.capabilities.keys()),
            "registration_time": datetime.now()
        }
        
        self.integration_stats["total_agents"] += 1
        self.integration_stats["active_agents"] += 1
        
        logger.info(f"æ™ºèƒ½ä½“ {agent.agent_id} æ³¨å†ŒæˆåŠŸ")
    
    async def assign_task(self, task: Dict[str, Any], 
                         preferred_agent: str = None) -> Dict[str, Any]:
        """åˆ†é…ä»»åŠ¡ç»™æ™ºèƒ½ä½“"""
        # é€‰æ‹©æœ€é€‚åˆçš„æ™ºèƒ½ä½“
        if preferred_agent and preferred_agent in self.agents:
            selected_agent = self.agents[preferred_agent]
        else:
            selected_agent = await self._select_best_agent(task)
        
        if not selected_agent:
            return {
                "success": False,
                "error": "æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„æ™ºèƒ½ä½“æ‰§è¡Œä»»åŠ¡"
            }
        
        # æ‰§è¡Œä»»åŠ¡
        result = await selected_agent.execute_task(task)
        
        # æ›´æ–°ç»Ÿè®¡
        self.integration_stats["completed_tasks"] += 1
        if result.get("learning_occurred"):
            self.integration_stats["learning_events"] += 1
        
        # è®°å½•åä½œäº‹ä»¶
        if result.get("execution_method") == "collaborative":
            self.integration_stats["collaboration_events"] += 1
        
        return {
            "task_result": result,
            "assigned_agent": selected_agent.agent_id,
            "agent_status": selected_agent.get_agent_status()
        }
    
    async def _select_best_agent(self, task: Dict[str, Any]) -> Optional[OrganicAgent]:
        """é€‰æ‹©æœ€é€‚åˆçš„æ™ºèƒ½ä½“"""
        task_type = task.get("type", "general")
        required_capabilities = self._analyze_task_requirements(task)
        
        best_agent = None
        best_score = 0.0
        
        for agent in self.agents.values():
            if agent.state == AgentState.ERROR:
                continue
            
            # è®¡ç®—åŒ¹é…åˆ†æ•°
            score = 0.0
            capability_count = 0
            
            for cap_name in required_capabilities:
                if cap_name in agent.capabilities:
                    capability = agent.capabilities[cap_name]
                    score += capability.proficiency_level * capability.success_rate
                    capability_count += 1
            
            # å¹³å‡åˆ†æ•°
            if capability_count > 0:
                avg_score = score / capability_count
                
                # è€ƒè™‘æ™ºèƒ½ä½“ç±»å‹åŒ¹é…
                if agent.agent_type == task_type:
                    avg_score *= 1.2  # ç±»å‹åŒ¹é…åŠ æˆ
                
                # è€ƒè™‘å½“å‰çŠ¶æ€
                if agent.state == AgentState.ACTIVE:
                    avg_score *= 1.1
                elif agent.state == AgentState.LEARNING:
                    avg_score *= 0.9
                
                if avg_score > best_score:
                    best_score = avg_score
                    best_agent = agent
        
        return best_agent
    
    def _analyze_task_requirements(self, task: Dict[str, Any]) -> List[str]:
        """åˆ†æä»»åŠ¡éœ€æ±‚ï¼ˆå¤ç”¨OrganicAgentçš„æ–¹æ³•ï¼‰"""
        task_type = task.get("type", "general")
        
        capability_mapping = {
            "code_analysis": ["code_analysis", "pattern_recognition"],
            "code_generation": ["code_generation", "problem_solving"],
            "debugging": ["debugging", "problem_solving"],
            "optimization": ["optimization", "performance_analysis"],
            "collaboration": ["communication", "coordination"],
            "general": ["problem_solving", "decision_making"]
        }
        
        return capability_mapping.get(task_type, ["problem_solving"])
    
    async def trigger_collective_learning(self, learning_data: Dict[str, Any]):
        """è§¦å‘é›†ä½“å­¦ä¹ """
        learning_task = {
            "type": "learning",
            "data": learning_data,
            "complexity": "medium"
        }
        
        # æ‰€æœ‰æ™ºèƒ½ä½“å‚ä¸å­¦ä¹ 
        learning_results = []
        for agent in self.agents.values():
            if agent.state != AgentState.ERROR:
                result = await agent.execute_task(learning_task)
                learning_results.append({
                    "agent_id": agent.agent_id,
                    "learning_result": result
                })
        
        self.integration_stats["learning_events"] += len(learning_results)
        
        return {
            "collective_learning_completed": True,
            "participating_agents": len(learning_results),
            "results": learning_results
        }
    
    async def get_ecosystem_status(self) -> Dict[str, Any]:
        """è·å–ç”Ÿæ€ç³»ç»ŸçŠ¶æ€"""
        agent_statuses = {}
        for agent_id, agent in self.agents.items():
            agent_statuses[agent_id] = agent.get_agent_status()
        
        # è®¡ç®—ç”Ÿæ€ç³»ç»ŸæŒ‡æ ‡
        total_capabilities = sum(len(agent.capabilities) for agent in self.agents.values())
        total_experiences = sum(len(agent.experiences) for agent in self.agents.values())
        total_knowledge_nodes = sum(agent.knowledge_graph.number_of_nodes() for agent in self.agents.values())
        
        avg_competence = sum(agent.self_assessment["overall_competence"] for agent in self.agents.values()) / len(self.agents) if self.agents else 0.0
        
        return {
            "ecosystem_overview": {
                "total_agents": len(self.agents),
                "active_agents": len([a for a in self.agents.values() if a.state == AgentState.ACTIVE]),
                "total_capabilities": total_capabilities,
                "total_experiences": total_experiences,
                "total_knowledge_nodes": total_knowledge_nodes,
                "average_competence": avg_competence
            },
            "integration_stats": self.integration_stats,
            "agent_details": agent_statuses,
            "collaboration_network": self._analyze_collaboration_network()
        }
    
    def _analyze_collaboration_network(self) -> Dict[str, Any]:
        """åˆ†æåä½œç½‘ç»œ"""
        network_stats = {
            "total_connections": 0,
            "collaboration_density": 0.0,
            "most_collaborative_agent": None,
            "collaboration_patterns": {}
        }
        
        if not self.agents:
            return network_stats
        
        # è®¡ç®—è¿æ¥æ•°
        total_connections = sum(len(agent.collaborators) for agent in self.agents.values())
        network_stats["total_connections"] = total_connections
        
        # è®¡ç®—åä½œå¯†åº¦
        max_possible_connections = len(self.agents) * (len(self.agents) - 1)
        if max_possible_connections > 0:
            network_stats["collaboration_density"] = total_connections / max_possible_connections
        
        # æ‰¾å‡ºæœ€å…·åä½œæ€§çš„æ™ºèƒ½ä½“
        max_collaborations = 0
        most_collaborative = None
        
        for agent in self.agents.values():
            collaboration_count = agent.performance_metrics["collaboration_sessions"]
            if collaboration_count > max_collaborations:
                max_collaborations = collaboration_count
                most_collaborative = agent.agent_id
        
        network_stats["most_collaborative_agent"] = most_collaborative
        
        return network_stats

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """Agent Zeroé›†æˆä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸ¤– Agent Zeroé›†æˆæ¼”ç¤º")
    print("=" * 50)
    
    # åˆå§‹åŒ–Agent Zeroé›†æˆ
    agent_zero = AgentZeroIntegration()
    
    # ç­‰å¾…é»˜è®¤æ™ºèƒ½ä½“åˆå§‹åŒ–
    await asyncio.sleep(1)
    
    # åˆ†é…ä»£ç åˆ†æä»»åŠ¡
    code_analysis_task = {
        "type": "code_analysis",
        "complexity": "medium",
        "content": "def fibonacci(n): return n if n <= 1 else fibonacci(n-1) + fibonacci(n-2)",
        "requirements": ["æ€§èƒ½åˆ†æ", "ä¼˜åŒ–å»ºè®®"]
    }
    
    result1 = await agent_zero.assign_task(code_analysis_task)
    print(f"âœ… ä»£ç åˆ†æä»»åŠ¡å®Œæˆ")
    print(f"   æ‰§è¡Œæ™ºèƒ½ä½“: {result1['assigned_agent']}")
    print(f"   ä»»åŠ¡æˆåŠŸ: {result1['task_result']['success']}")
    
    # åˆ†é…ä»£ç ç”Ÿæˆä»»åŠ¡
    code_generation_task = {
        "type": "code_generation",
        "complexity": "high",
        "requirements": ["ç”Ÿæˆä¼˜åŒ–çš„æ–æ³¢é‚£å¥‘å‡½æ•°", "åŒ…å«æ³¨é‡Šå’Œæµ‹è¯•"]
    }
    
    result2 = await agent_zero.assign_task(code_generation_task)
    print(f"âœ… ä»£ç ç”Ÿæˆä»»åŠ¡å®Œæˆ")
    print(f"   æ‰§è¡Œæ™ºèƒ½ä½“: {result2['assigned_agent']}")
    print(f"   æ‰§è¡Œæ–¹æ³•: {result2['task_result']['result']['execution_method']}")
    
    # è§¦å‘é›†ä½“å­¦ä¹ 
    learning_data = {
        "topic": "Pythonæ€§èƒ½ä¼˜åŒ–",
        "examples": ["åŠ¨æ€è§„åˆ’", "ç¼“å­˜æœºåˆ¶", "ç®—æ³•å¤æ‚åº¦åˆ†æ"],
        "best_practices": ["é¿å…é‡å¤è®¡ç®—", "ä½¿ç”¨å†…ç½®å‡½æ•°", "é€‰æ‹©åˆé€‚çš„æ•°æ®ç»“æ„"]
    }
    
    learning_result = await agent_zero.trigger_collective_learning(learning_data)
    print(f"âœ… é›†ä½“å­¦ä¹ å®Œæˆ")
    print(f"   å‚ä¸æ™ºèƒ½ä½“: {learning_result['participating_agents']} ä¸ª")
    
    # è·å–ç”Ÿæ€ç³»ç»ŸçŠ¶æ€
    ecosystem_status = await agent_zero.get_ecosystem_status()
    
    print(f"\nğŸ“Š Agent Zeroç”Ÿæ€ç³»ç»ŸçŠ¶æ€:")
    print(f"   æ€»æ™ºèƒ½ä½“æ•°: {ecosystem_status['ecosystem_overview']['total_agents']}")
    print(f"   æ´»è·ƒæ™ºèƒ½ä½“: {ecosystem_status['ecosystem_overview']['active_agents']}")
    print(f"   æ€»èƒ½åŠ›æ•°: {ecosystem_status['ecosystem_overview']['total_capabilities']}")
    print(f"   æ€»ç»éªŒæ•°: {ecosystem_status['ecosystem_overview']['total_experiences']}")
    print(f"   å¹³å‡èƒ½åŠ›: {ecosystem_status['ecosystem_overview']['average_competence']:.2f}")
    print(f"   åä½œå¯†åº¦: {ecosystem_status['collaboration_network']['collaboration_density']:.2f}")
    
    print(f"\nğŸ¯ é›†æˆç»Ÿè®¡:")
    print(f"   å®Œæˆä»»åŠ¡: {ecosystem_status['integration_stats']['completed_tasks']}")
    print(f"   åä½œäº‹ä»¶: {ecosystem_status['integration_stats']['collaboration_events']}")
    print(f"   å­¦ä¹ äº‹ä»¶: {ecosystem_status['integration_stats']['learning_events']}")

if __name__ == "__main__":
    asyncio.run(main())

